{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/train.tsv',delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38225478e160d6f3f214684b91f551a72715d2ca"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3ff245a7e58c2bb8cada4101bef84fa15011f01"},"cell_type":"code","source":"sentiment = data['Sentiment']\nfeature = data['Phrase']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7335ca2c3ded49dc0ff70e27abeac401925f289"},"cell_type":"code","source":"import re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4b43e190aeefa9e40c44ee07844ebedd585ebef"},"cell_type":"code","source":"lemma = WordNetLemmatizer()\ndef preprop(text):\n    text = text.lower()\n    text = re.sub('[^a-z]',' ',text)\n    text = text.split()\n    text = [lemma.lemmatize(word) for word in text if word not in stopwords.words('english')]\n    return ' '.join(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"001930d5f9974828fb686bc584e25f72590aaac2"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(ngram_range=(1,3),max_features=6000,stop_words='english')\nclean_feature=[]\ndef train(feature,sentiment,classifier):\n    for i in feature:\n        clean_feature.append(preprop(i))\n    feat_vector = tfidf.fit_transform(clean_feature).toarray()\n    classifier.fit(feat_vector,sentiment)\n    return classifier,feat_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"582edd27a28eb8535ab986f18809d32fe4bb0f53"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nclassifier,feat_vector = train(feature,sentiment,nb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"840abee01ea35bc0a3d9c6dc72275b650945fcbd"},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abaabb8c4bcb38ee8d9b1c6ed581fefe93eeb8fb"},"cell_type":"code","source":"classifiers = 'sentiment_analyser.sav'\ntfidfs = 'tfidf.sav'\npickle.dump(classifier, open(classifiers, 'wb'))\npickle.dump(tfidf, open(tfidfs, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98e0cd2a9fe195aa7c00560148d04fdb522648e2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}